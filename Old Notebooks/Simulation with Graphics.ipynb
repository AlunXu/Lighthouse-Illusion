{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba16fdaa",
   "metadata": {},
   "source": [
    "# Visualise difference cases of lighthouse illusion (from python script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a53ff",
   "metadata": {},
   "source": [
    "The visualisation by VPython library uses browser window. In notebook only the static graphics can be shown by the canvas and hence animation cannot be shown directly - I haven't found any solution to this. Please let me know if you know how to tackle this, though not of importance as we can see it by executing the script directly.\\\n",
    "\n",
    "**Therefore for now please run the python script `LighthouseSimulation.py` directly to see the simulation.** \\\n",
    "Please change the `distance` variable to modify the distance between the person and the lighthouse.\n",
    "- `distance` = 20 (very close to the lighthouse), no illusion. An interesting finding is that, even at this short distance, the rotating light beam seems move horizontally already. (meaning the effects of perspective, or the prior from our explanation approach, are significant)\n",
    "- `distance` = 100, weak illusion. There are some indications that the beam comes from the front, but we can still probably realise it is from the back as the convergence is not significant.\n",
    "- `distance` = 350, strong illusion. The feeling of convergence in the front is strong. It may be more obvious if there are more noises in the distant end. \n",
    "\n",
    "I believe the simulation matches our expectation =)\n",
    "\n",
    "For the graphic visualisation:\n",
    "- Scroll up / down (for trackpad: pinch two fingers open / closed): **zoom in / out**\n",
    "    - please note that the rate of zoom in / out through pinching is very fast, and the scene will quickly disappear - If so, please re-run the cell.\n",
    "- Press the right click and drag: **rotate the view angle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a1e68",
   "metadata": {},
   "source": [
    "# Prior Simulation & Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -install vpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887a720a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T12:21:41.159561Z",
     "start_time": "2022-10-29T12:21:41.134043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "if (typeof Jupyter !== \"undefined\") { window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")};}else{ element.textContent = ' ';}",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vpython import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b48381",
   "metadata": {},
   "source": [
    "`PriorSimulation.py` generates the simulated prior **before projection**, with graphic visualisation. \\\n",
    "The simulated prior is represented by four 2d numpy arrays, \\\n",
    "- surfaces_left_top\n",
    "- surfaces_left_bottom\n",
    "- surfaces_right_top\n",
    "- surfaces_right_bottom \n",
    "\n",
    "each of which contains the **(x,y) coordinate** and the **distance** of the respective corner of the simulated surface \\\n",
    "\n",
    "For the graphic visualisation:\n",
    "- Scroll up / down (for trackpad: pinch two fingers open / closed): **zoom in / out**\n",
    "    - please note that the rate of zoom in / out through pinching is very fast, and the scene will quickly disappear - If so, please re-run the cell.\n",
    "- Press the right click and drag: **rotate the view angle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1494d6b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T23:11:35.753980Z",
     "start_time": "2022-10-29T23:11:35.730864Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "if (typeof Jupyter !== \"undefined\") { window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")};}else{ element.textContent = ' ';}",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "canvas()\n",
    "%run vPython/PriorSimulation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d33a9",
   "metadata": {},
   "source": [
    "# Project the 3D prior to 2D through pinhole camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d42b6",
   "metadata": {},
   "source": [
    "# Visualise the prior distribution through difference angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc859c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T23:11:59.686092Z",
     "start_time": "2022-10-29T23:11:59.675126Z"
    }
   },
   "outputs": [],
   "source": [
    "def homogenise(points: np.array):\n",
    "    \"\"\"Converts non-homogeneous 2D or 3D coordinates into homogeneous coordinates.\n",
    "    For example\n",
    "    [x1 x2 x3]    [x1 x2 x3]\n",
    "    [y1 y2 y3] -> [y1 y2 y3]\n",
    "                  [1  1  1]\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : numpy.array, shape (dimensions, nr_points)\n",
    "    Returns\n",
    "    --------\n",
    "    points : numpy.array, shape (dimensions+1, nr_points)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.concatenate((points, np.ones((1, points.shape[1]))), axis=0)\n",
    "\n",
    "def forwardprojectP(points: np.array, P: np.array, image_size, image=None):\n",
    "    \"\"\"\n",
    "    # Project 3D points, defined by [X Y Z]', onto an image plane defined by a 3x4 projection matrix P.\n",
    "    # Returns those 3D points that are withing the FOV of the camera (i.e. filters out those points\n",
    "      that are outside of the FOV), the corresponding uv-image coordinates, and a depth map.\n",
    "    \n",
    "    # Additionally, if an image is given, RGB for each 3D point is returned - None \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points : numpy.array, shape (3, nr_points)\n",
    "    P : numpy array, shape (3, 4), Camera projection matrix P = K[R | t]\n",
    "        In our case, as camera is positioned in the center, \n",
    "        [R | t] = [1, 0, 0, 0]\n",
    "                  [0, 1, 0, 0]\n",
    "                  [0, 0, 1, 0]\n",
    "        K = [f, 0, px ]    [0.01,    0, 216]\n",
    "            [0, f, py ] => [   0, 0.01, 216] \n",
    "            [0, 0,  1 ]    [   0,    0,   1]\n",
    "                  \n",
    "    image_size : tuple\n",
    "            Image size, (512, 512)\n",
    "    image : numpy.array, optional\n",
    "            Image used for defining colors for each point (default is None).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Our Case:\n",
    "    (3D points, uv-coordinates, depth map) : numpy array\n",
    "        If no image is given (i.e. is None). Shapes are (3, nr_points), (3, nr_points) and (rows, cols)\n",
    "    (3D points, uv-coordinates, RGB, depth map) : numpy array\n",
    "        If image is given. Shapes are (3, nr_points), (3, nr_points), (3, nr_points) and (rows, cols)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the image_size into a tuple. It might already be a tuple, but let's just make sure\n",
    "    image_size = (int(image_size[0]), int(image_size[1]))\n",
    "    depth_map = np.ones(image_size) * np.nan\n",
    "\n",
    "    try:\n",
    "        # Convert points into homogeneous form\n",
    "        points = homogenise(points)\n",
    "\n",
    "        # Project points to image\n",
    "        uv = np.matmul(P, points)\n",
    "\n",
    "        # Filter points that fall behind the camera\n",
    "        mask = uv[2, :] < 0.0\n",
    "        uv = uv[:, ~mask]\n",
    "        points = points[:, ~mask]\n",
    "\n",
    "        # Normalize coordinates\n",
    "        uv[0, :] /= uv[2, :]\n",
    "        uv[1, :] /= uv[2, :]\n",
    "        uv[2, :] /= uv[2, :]\n",
    "\n",
    "        # Mask out points that don't fall withing the given image (i.e. are outside of FOV)\n",
    "        mask = (uv[0, :] < 0) | (uv[0, :] > (image_size[1] - 1)) | (uv[1, :] < 0) | (uv[1, :] > (image_size[0] - 1))\n",
    "        points = points[:, ~mask]\n",
    "        uv = uv[:, ~mask]\n",
    "        \n",
    "#         print(np.round(uv[1, :]).astype(int))\n",
    "        \n",
    "        # Generate a depth map\n",
    "        depth_map[np.round(uv[1, :]).astype(int), np.round(uv[0, :]).astype(int)] = points[2, :]\n",
    "\n",
    "        # Handle colors, if given\n",
    "        if image is None:\n",
    "            return points[:3, :], uv, depth_map\n",
    "        else:\n",
    "            RGB = image[np.round(uv[1, :]).astype(int), np.round(uv[0, :]).astype(int), :]\n",
    "            return points[:3, :], uv, RGB, depth_map\n",
    "    except Exception as e:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf549e64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T07:54:22.070566Z",
     "start_time": "2022-10-31T07:54:21.868839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illusion in Bayesian.ipynb      depth.npy\r\n",
      "LICENSE                         depth_0.npy\r\n",
      "README.md                       \u001b[1m\u001b[36mopen3D\u001b[m\u001b[m/\r\n",
      "Simulation with Graphics.ipynb  \u001b[1m\u001b[36mvPython\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[36mSnapshots\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce770243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T07:56:31.951969Z",
     "start_time": "2022-10-31T07:56:31.928320Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[1;31m[Open3D Error] (open3d::visualization::rendering::EngineInstance::EngineInstance()) /Users/runner/work/Open3D/Open3D/cpp/open3d/visualization/rendering/filament/FilamentEngine.cpp:123: EGL Headless is not supported on this platform.\n\u001b[0;m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/Research:Vision/Lighthouse-Illusion/open3D/OnePriorSimulation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTriangleMesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sphere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_vertex_normals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m u = o3d.visualization.draw(\n\u001b[0m\u001b[1;32m     10\u001b[0m     mesh, raw_mode=False, non_blocking_and_return_uid=True)\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ---------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/open3d/visualization/draw.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(geometry, title, width, height, actions, lookat, eye, up, field_of_view, bg_color, bg_image, ibl, ibl_intensity, show_skybox, show_ui, raw_mode, point_size, line_width, animation_time_step, animation_duration, rpc_interface, on_init, on_animation_frame, on_animation_tick, non_blocking_and_return_uid)\u001b[0m\n\u001b[1;32m     55\u001b[0m          non_blocking_and_return_uid=False):\n\u001b[1;32m     56\u001b[0m     \u001b[0mgui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mO3DVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[1;31m[Open3D Error] (open3d::visualization::rendering::EngineInstance::EngineInstance()) /Users/runner/work/Open3D/Open3D/cpp/open3d/visualization/rendering/filament/FilamentEngine.cpp:123: EGL Headless is not supported on this platform.\n\u001b[0;m"
     ]
    }
   ],
   "source": [
    "%run open3D/OnePriorSimulation.py"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "579.852px",
    "left": "1375px",
    "right": "20px",
    "top": "775px",
    "width": "477px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
